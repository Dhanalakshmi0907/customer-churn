# -*- coding: utf-8 -*-
"""source

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12KGOqX3fFuIgnVXgBKlK2Ko2ts80Dp5j
"""

#upload files
from google.colab import files
uploaded=files.upload()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import csv
import math
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Import necessary libraries
import pandas as pd

# Load the dataset (replace with your actual file path)
data = pd.read_csv('/content/customer_churn.csv')  # Make sure the file exists in your working directory

# Display the shape of the dataset
print("Dataset Shape:")
print(data.shape)  # Outputs (rows, columns)

# Optional: View the first few rows
print("\nPreview of the dataset:")
print(data.head())

# Import necessary library
import pandas as pd

# Load the dataset (update the file path if needed)
data = pd.read_csv('/content/customer_churn.csv')  # Make sure this file exists in your working directory

# Display the first 5 rows of the dataset
print("First 5 Rows of the Dataset:")
print(data.head())  # Shows the top 5 records

# Import necessary library
import pandas as pd

# Set display options for better readability
pd.set_option('display.max_columns', None)     # Show all columns
pd.set_option('display.width', 1000)           # Set display width
pd.set_option('display.max_colwidth', None)    # Show full content in each column

# Load the dataset
data = pd.read_csv('customer_churn.csv')

# Display the first 5 rows of the dataset
print("Formatted View of First 5 Rows:")
print(data.head())

# Import necessary library
import pandas as pd

# Load the dataset (update the file path if needed)
data = pd.read_csv('/content/customer_churn.csv')

# Display dataset information
print("Dataset Info:")
data.info()

# Import necessary library
import pandas as pd

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Drop the customerID column (not useful for modeling)
if 'customerID' in data.columns:
    data = data.drop('customerID', axis=1)

# Display remaining columns and first few rows
print("First 5 Rows After Dropping 'customerID':")
print(data.head())

# Optional: Print updated column names
print("\nRemaining Columns:")
print(data.columns.tolist())

# Import necessary libraries
import pandas as pd

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Check if 'gender' column exists
if 'Gender' in data.columns:
    # Display unique gender values
    print("Unique Gender Values:")
    print(data['Gender'].unique())

    # Display gender distribution
    print("\nGender Distribution:")
    print(data['Gender'].value_counts())

    # Encode gender (optional, for modeling)
    data['Gender_encoded'] = data['Gender'].map({'Female': 0, 'Male': 1})

    # Display first few rows with encoded gender
    print("\nFirst 5 Rows with Encoded Gender:")
    print(data[['Gender', 'Gender_encoded']].head())
else:
    print("'Gender' column not found in the dataset.")

# Import necessary library
import pandas as pd

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Loop through each column and print unique values
print("Unique Values in Each Column:\n")
for column in data.columns:
    unique_vals = data[column].unique()
    print(f"{column} ({len(unique_vals)} unique):")
    print(unique_vals)
    print("-" * 40)

# Import necessary library
import pandas as pd

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Check for null values
print("Null Values in Each Column:\n")
null_counts = data.isnull().sum()

# Display columns with at least one null value
print(null_counts[null_counts > 0])

# Optional: Summary if no nulls
if null_counts.sum() == 0:
    print("No missing values found in the dataset.")

# Import necessary library
import pandas as pd

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Check the balance of the target variable (e.g., 'Churn')
if 'Balance' in data.columns:
    print("Class Balance in 'Balance' column:")
    print(data['Balance'].value_counts())

    # Optional: Display the percentage distribution
    print("\nPercentage Distribution:")
    print(data['Balance'].value_counts(normalize=True) * 100)
else:
    print("'Balance' column not found in the dataset.")

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Example: Plotting churn over time (if you have a 'Date' or 'Month' column)
# Make sure there's a 'Date' column in the dataset, or use any time-related feature.

# Example: Assume you have a 'Date' column and 'Churn' column
# If you have a 'Date' column, convert it to datetime format (if not already)
if 'Exited' in data.columns:
    data['Exited'] = pd.to_datetime(data['Exited'])

    # Resample data by month and calculate churn rate
    monthly_churn = data.resample('M', on='Exited')['Balance'].mean()

    # Plotting the churn rate over time (monthly)
    plt.figure(figsize=(10,6))
    plt.plot(monthly_churn.index, monthly_churn.values, marker='o', linestyle='-', color='b')
    plt.title('Customer Churn Rate Over Time')
    plt.xlabel('Exited')
    plt.ylabel('Churn Rate')
    plt.grid(True)
    plt.xticks(rotation=45)
    plt.show()
else:
    print("'Exited' column not found in the dataset.")

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Example: Bar chart for churn distribution based on 'Gender'
if 'Gender' in data.columns and 'Exited' in data.columns:
    # Group by 'Gender' and calculate churn count for each gender
    churn_by_gender = data.groupby('Gender')['Exited'].value_counts().unstack().fillna(0)

    # Plotting the bar chart
    churn_by_gender.plot(kind='bar', stacked=True, figsize=(10, 6), color=['lightblue', 'salmon'])

    # Customize the plot
    plt.title('Churn Distribution by Gender')
    plt.xlabel('Gender')
    plt.ylabel('Count')
    plt.xticks(rotation=0)  # Rotate x-axis labels for better readability
    plt.legend(title='Churn Status', labels=['Not Churned', 'Churned'])
    plt.tight_layout()
    plt.show()
else:
    print("'Gender' or 'Exited' column not found in the dataset.")

# Import necessary libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Example: Histogram of MonthlyCharges based on Churn status
if 'Age' in data.columns and 'Exited' in data.columns:
    # Separate data based on churn status (Churn = 1, No Churn = 0)
    churned = data[data['Exited'] == 1]['Age']
    not_churned = data[data['Exited'] == 0]['Age']

    # Plotting the histograms
    plt.figure(figsize=(10, 6))
    plt.hist(churned, bins=30, alpha=0.7, label='Churned', color='salmon')
    plt.hist(not_churned, bins=30, alpha=0.7, label='Not Churned', color='lightblue')

    # Customizing the plot
    plt.title('Distribution of Monthly Charges by Churn Status')
    plt.xlabel('Age')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(True)
    plt.show()
else:
    print("'Age' or 'Exited' column not found in the dataset.")

import seaborn as sns
import matplotlib.pyplot as plt

# Create a boxplot for 'Age' vs. 'Exited'
plt.figure(figsize=(10, 6))
sns.boxplot(data=data, x='Exited', y='Age', palette='coolwarm')

# Customize the plot
plt.title('Boxplot of Age by Exited Status')
plt.xlabel('Exited Status')
plt.ylabel('Age')
plt.xticks([0, 1], ['Not Exited', 'Exited'])
plt.grid(True)
plt.show()

# Import necessary libraries
import pandas as pd

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Rename columns 'MonthlyCharges' to 'Age' and 'Churn' to 'Exited'
data = data.rename(columns={'MonthlyCharges': 'Age', 'Churn': 'Exited'})

# Display the first few rows to confirm the changes
print("First 5 Rows After Renaming Columns:")
print(data.head())

# Import necessary libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('customer_churn.csv')

# Rename columns if needed (e.g., 'MonthlyCharges' to 'Age', 'Churn' to 'Exited')
data = data.rename(columns={'MonthlyCharges': 'Age', 'Churn': 'Exited'})

# Select the numerical features you want to include in the correlation matrix
numerical_features = ['Age', 'Tenure', 'Balance', 'Exited']

# Calculate the correlation matrix
correlation_matrix = data[numerical_features].corr()

# Create a heatmap using seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=0.5, fmt='.2f')

# Customize the plot
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Rename columns if necessary
data = data.rename(columns={'MonthlyCharges': 'Age', 'Churn': 'Exited'})

# Example: Plot 'TotalCharges' over 'Tenure', grouped by 'Exited' (churned or not)
# First, make sure there are no missing or non-numeric values
data = data[['Tenure', 'Balance', 'Exited']].dropna()
data['Balance'] = pd.to_numeric(data['Balance'], errors='coerce')
data = data.dropna()

# Group the data by 'Exited' and calculate average TotalCharges per Tenure
grouped = data.groupby(['Exited', 'Tenure'])['Balance'].mean().reset_index()

# Create the line plot iteratively for each Exited group
plt.figure(figsize=(10, 6))

for status in grouped['Exited'].unique():
    subset = grouped[grouped['Exited'] == status]
    label = 'Exited' if status == 1 else 'Stayed'
    plt.plot(subset['Tenure'], subset['Balance'], marker='o', label=label)

# Customizing the plot
plt.title('Average Total Charges by Tenure (Exited vs. Stayed)')
plt.xlabel('Tenure (Months)')
plt.ylabel('Average Total Charges')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('/content/customer_churn.csv')

# Rename columns for clarity (if not already renamed)
data = data.rename(columns={'MonthlyCharges': 'Age', 'Churn': 'Exited'})

# Ensure numeric data and drop rows with missing or invalid values
data['Balance'] = pd.to_numeric(data['Balance'], errors='coerce')
data = data[['Age', 'Balance', 'Exited']].dropna()

# Create scatter plot iteratively for each class in 'Exited'
plt.figure(figsize=(10, 6))
colors = {0: 'blue', 1: 'red'}  # 0 = Not Exited, 1 = Exited

for status in data['Exited'].unique():
    subset = data[data['Exited'] == status]
    label = 'Exited' if status == 1 else 'Stayed'
    plt.scatter(subset['Age'], subset['Balance'], label=label, alpha=0.6, c=colors[status])

# Customize plot
plt.title('Scatter Plot of Age vs Total Charges by Churn Status')
plt.xlabel('Age')
plt.ylabel('Balance')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # Needed for 3D plotting

# Load the dataset
data = pd.read_csv('customer_churn.csv')

# Rename columns for clarity (if needed)
data = data.rename(columns={'MonthlyCharges': 'Age', 'Churn': 'Exited'})

# Ensure relevant columns are numeric and drop missing values
data['Balance'] = pd.to_numeric(data['Balance'], errors='coerce')
data = data[['Age', 'Tenure', 'Balance', 'Exited']].dropna()

# Setup for 3D scatter plot
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

# Define colors for churned vs not churned
colors = {0: 'blue', 1: 'red'}
labels = {0: 'Stayed', 1: 'Exited'}

# Plot each churn status separately
for status in data['Exited'].unique():
    subset = data[data['Exited'] == status]
    ax.scatter(
        subset['Age'], subset['Tenure'], subset['Balance'],
        c=colors[status], label=labels[status], alpha=0.6
    )

# Set labels and title
ax.set_xlabel('Age')
ax.set_ylabel('Tenure (Months)')
ax.set_zlabel('Balance')
ax.set_title('3D Scatter Plot of Customers by Churn Status')
ax.legend()
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load and prepare the dataset
data = pd.read_csv('customer_churn.csv')

# Rename columns (if needed)
data = data.rename(columns={'MonthlyCharges': 'Age', 'Churn': 'Exited'})

# Select relevant numeric features and drop missing values
data = data[['Age', 'Tenure']].dropna()

# Convert to NumPy array
X = data.values

# Number of clusters
k = 2

# Randomly initialize centroids from data
np.random.seed(42)
initial_centroids = X[np.random.choice(X.shape[0], k, replace=False)]

# Function to compute Euclidean distance from points to centroids
def compute_distances(X, centroids):
    distances = np.zeros((X.shape[0], k))
    for i in range(k):
        distances[:, i] = np.linalg.norm(X - centroids[i], axis=1)
    return distances

# Run K-Means iterations
max_iter = 10
for iteration in range(max_iter):
    # Step 1: Assign clusters
    distances = compute_distances(X, initial_centroids)
    cluster_labels = np.argmin(distances, axis=1)

    # Step 2: Recompute centroids
    new_centroids = np.array([X[cluster_labels == i].mean(axis=0) for i in range(k)])

    # Check for convergence
    if np.allclose(initial_centroids, new_centroids):
        break

    initial_centroids = new_centroids

# Plot the clustered data
colors = ['red', 'blue']
plt.figure(figsize=(8, 6))
for i in range(k):
    plt.scatter(X[cluster_labels == i][:, 0], X[cluster_labels == i][:, 1],
                c=colors[i], label=f'Cluster {i}', alpha=0.6)

# Plot centroids
plt.scatter(initial_centroids[:, 0], initial_centroids[:, 1],
            marker='x', c='black', s=200, label='Centroids')

# Customize plot
plt.xlabel('Age')
plt.ylabel('Tenure')
plt.title('Manual K-Means Clustering (Age vs Tenure)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import csv
import math

# Initialize list to hold Age values
ages = []

# Read the CSV file
with open('customer_churn.csv', 'r') as file:
    reader = csv.DictReader(file)
    for row in reader:
        try:
            # Assume 'MonthlyCharges' column is renamed to 'Age'
            age = float(row['MonthlyCharges'])  # or use 'Age' if already renamed
            ages.append(age)
        except (ValueError, KeyError):
            continue  # Skip invalid or missing values

# Ensure we have data
if len(ages) == 0:
    print("No valid Age data found.")
else:
    # Step 1: Calculate mean
    n = len(ages)
    mean_age = sum(ages) / n

    # Step 2: Calculate variance
    variance = sum((x - mean_age) ** 2 for x in ages) / n

    # Step 3: Calculate standard deviation
    std_dev = math.sqrt(variance)

    # Output result
    print(f"Standard Deviation of Age (MonthlyCharges): {std_dev:.2f}")

import csv

# Initialize a list to store Age (MonthlyCharges) values
ages = []

# Read the CSV file
with open('/content/customer_churn.csv', 'r') as file:
    reader = csv.DictReader(file)
    for row in reader:
        try:
            # Replace 'MonthlyCharges' with 'Age' if renamed earlier
            age = float(row['MonthlyCharges'])
            ages.append(age)
        except (ValueError, KeyError):
            continue  # Skip rows with missing or non-numeric values

# Check if list has data
if not ages:
    print("No valid Age data found.")
else:
    # Calculate mean
    n = len(ages)
    mean_age = sum(ages) / n

    # Calculate variance
    variance = sum((x - mean_age) ** 2 for x in ages) / n

    # Print the result
    print(f"Variance of Age (MonthlyCharges): {variance:.2f}")

import csv

# Load your dataset
filename = '/content/customer_churn.csv'

# Initialize column-wise counters
missing_counts = {}
total_rows = 0

with open(filename, 'r') as file:
    reader = csv.DictReader(file)
    headers = reader.fieldnames

    # Initialize missing count dict with 0 for each column
    for header in headers:
        missing_counts[header] = 0

    # Count missing (empty or blank) values
    for row in reader:
        total_rows += 1
        for header in headers:
            value = row[header]
            if value is None or value.strip() == '':
                missing_counts[header] += 1

# Print the summary
print(f"\nMissing Value Report (Out of {total_rows} rows):\n")
for column, count in missing_counts.items():
    percent = (count / total_rows) * 100
    print(f"{column}: {count} missing ({percent:.2f}%)")

import csv

# Function to guess the type of a value
def guess_type(value):
    if value.strip() == '':
        return 'missing'
    try:
        int(value)
        return 'int'
    except ValueError:
        try:
            float(value)
            return 'float'
        except ValueError:
            return 'str'

# Read file and track types
filename = '/content/customer_churn.csv'
type_counts = {}
total_rows = 0

with open(filename, 'r') as file:
    reader = csv.DictReader(file)
    headers = reader.fieldnames

    # Initialize type counters per column
    for header in headers:
        type_counts[header] = {'int': 0, 'float': 0, 'str': 0, 'missing': 0}

    for row in reader:
        total_rows += 1
        for header in headers:
            value = row[header]
            inferred_type = guess_type(value)
            type_counts[header][inferred_type] += 1

# Report inferred data type per column
print("\nInferred Data Types per Column (based on majority type):\n")
for col, types in type_counts.items():
    most_common = max(types, key=types.get)
    print(f"{col}: {most_common} (counts: {types})")

import csv
import math

# Function to calculate Pearson's Correlation Coefficient
def pearson_correlation(x, y):
    n = len(x)
    if n == 0:  # Check for empty list
        return float('nan')  # Return NaN if empty to avoid division by zero
    mean_x = sum(x) / n
    mean_y = sum(y) / n

    numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(n))
    denominator_x = math.sqrt(sum((x[i] - mean_x) ** 2 for i in range(n)))
    denominator_y = math.sqrt(sum((y[i] - mean_y) ** 2 for i in range(n)))

    if denominator_x == 0 or denominator_y == 0: # Check for zero denominator
        return float('nan')  # Return NaN if denominator is zero to avoid division by zero
    else:
        return numerator / (denominator_x * denominator_y)

# Read the dataset
# Use the absolute file path used earlier
filename = '/content/customer_churn.csv'
ages = []
tenures = []
total_charges = []

with open(filename, 'r') as file:
    reader = csv.DictReader(file)
    for row in reader:
        try:
            # Replace 'MonthlyCharges' with 'Age' if renamed earlier
            age = float(row['MonthlyCharges'])
            tenure = float(row['Tenure'])
            # Handle empty or invalid 'TotalCharges' values
            total_charge = float(row['TotalCharges']) if row['TotalCharges'] != ' ' else 0.0

            # Collect the data into lists
            ages.append(age)
            tenures.append(tenure)
            total_charges.append(total_charge)
        except (ValueError, KeyError):
            continue  # Skip rows with missing or invalid data

# Perform correlation analysis
age_tenure_corr = pearson_correlation(ages, tenures)
age_totalcharge_corr = pearson_correlation(ages, total_charges)
tenure_totalcharge_corr = pearson_correlation(tenures, total_charges)

# Print results
print(f"Pearson Correlation between Age and Tenure: {age_tenure_corr:.2f}")
print(f"Pearson Correlation between Age and TotalCharges: {age_totalcharge_corr:.2f}")
print(f"Pearson Correlation between Tenure and TotalCharges: {tenure_totalcharge_corr:.2f}")

import csv
import math

# Function to calculate mean
def calculate_mean(data):
    if not data:  # Check if the list is empty
        return 0  # or float('nan') if you prefer to represent it as NaN
    return sum(data) / len(data)

# Function to calculate standard deviation
def calculate_std_dev(data, mean):
    variance = sum((x - mean) ** 2 for x in data) / len(data)
    return math.sqrt(variance)

import csv

# Function for Label Encoding
def label_encode(column_values):
    unique_values = list(set(column_values))
    encoding_map = {value: index for index, value in enumerate(unique_values)}
    return [encoding_map[value] for value in column_values], encoding_map

# Read the dataset
filename = 'customer_churn.csv'
genders = []  # Assume column 'Gender' is categorical

with open(filename, 'r') as file:
    reader = csv.DictReader(file)
    for row in reader:
        try:
            gender = row['Gender']  # Replace with actual categorical column if needed
            genders.append(gender)
        except (ValueError, KeyError):
            continue  # Skip rows with missing or invalid data

# Apply label encoding
encoded_genders, encoding_map = label_encode(genders)

# Output the results
print(f"Original Genders: {genders[:10]}")
print(f"Encoded Genders: {encoded_genders[:10]}")
print(f"Encoding Mapping: {encoding_map}")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Step 1: Load the dataset
# Assume the dataset is a CSV file called 'customer_churn.csv'
df = pd.read_csv('/content/customer_churn.csv')

# Step 2: Basic Data Inspection
print(df.info())  # Show data types and null values
print(df.head())  # Display first 5 rows

# Step 3: Descriptive statistics for features related to behavior
# Calculate mean, median, variance for features
behavior_columns = ['MonthlyCharges', 'Tenure', 'TotalCharges']

# Descriptive statistics for churned vs non-churned customers
churned_customers = df[df['Exited'] == 1]
non_churned_customers = df[df['Exited'] == 0]

# Summary statistics for behavior of churned customers
print("Churned Customers - Descriptive Statistics")
print(churned_customers[behavior_columns].describe())

# Summary statistics for behavior of non-churned customers
print("Non-Churned Customers - Descriptive Statistics")
print(non_churned_customers[behavior_columns].describe())

# Step 4: Statistical Tests
# Check if the behavior between churned and non-churned customers is significantly different
# Using a t-test to compare means for 'MonthlyCharges' between churned and non-churned customers
t_stat, p_value = stats.ttest_ind(churned_customers['MonthlyCharges'], non_churned_customers['MonthlyCharges'])
print(f"T-test for MonthlyCharges: t-statistic = {t_stat}, p-value = {p_value}")

# Step 5: Correlation Analysis
# Find correlation between features like 'MonthlyCharges', 'Tenure', 'TotalCharges' with churn status
correlation = df[behavior_columns + ['Exited']].corr()
print("Correlation Analysis:")
print(correlation)

# Step 6: Visualization
# Visualizing behavior of churned vs non-churned customers
plt.figure(figsize=(14, 6))

# Monthly Charges distribution
plt.subplot(1, 3, 1)
sns.histplot(churned_customers['MonthlyCharges'], color='red', kde=True, label='Churned', stat='density')
sns.histplot(non_churned_customers['MonthlyCharges'], color='green', kde=True, label='Non-Churned', stat='density')
plt.title('Monthly Charges Distribution')
plt.legend()

# Tenure distribution
plt.subplot(1, 3, 2)
sns.histplot(churned_customers['Tenure'], color='red', kde=True, label='Churned', stat='density')
sns.histplot(non_churned_customers['Tenure'], color='green', kde=True, label='Non-Churned', stat='density')
plt.title('Tenure Distribution')
plt.legend()

# Total Charges distribution
plt.subplot(1, 3, 3)
sns.histplot(churned_customers['TotalCharges'], color='red', kde=True, label='Churned', stat='density')
sns.histplot(non_churned_customers['TotalCharges'], color='green', kde=True, label='Non-Churned', stat='density')
plt.title('Total Charges Distribution')
plt.legend()

plt.tight_layout()
plt.show()

# Step 7: Boxplot for comparison of behaviors
plt.figure(figsize=(10, 6))

# Boxplot for MonthlyCharges vs Exited (Churned or Not)
sns.boxplot(x='Exited', y='MonthlyCharges', data=df)
plt.title('Boxplot of Monthly Charges for Churned vs Non-Churned Customers')
plt.xlabel('Exited (0 = Non-Churned, 1 = Churned)')
plt.ylabel('Monthly Charges')
plt.show()

# Step 8: Behavior Analysis - Churn Patterns
# For instance, check the behavior of churned customers as they approach the time of churn (e.g., monthly usage patterns)